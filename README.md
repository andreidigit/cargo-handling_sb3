# CargoHandling

Cargo Handling - микросервисное приложение для управления логистическими операциями. Система обеспечивает управление
складами, отслеживание грузов, обработку заказов и оптимизацию маршрутов доставки.

## Функциональные

- CRUD доступна авторизованным пользователям, с правами read and write.
- CRUD модели выполняется при успешной фильтрации запросов бизнес правилами.
- Модели отражают текущий статус процесса.

## Нефункциональные

- Модели Склад, Грузы, Заказы, Маршруты - хранятся в соответствующих сущностях.
- Чтение модели по неблокирующему, с точки зрения микро-сервисного взаимодействия, GET запросу.
- Создание, обновление, удаление асинхронный POST и DELETE запросы.
- Внутренняя коммуникация асинхронная.
- Изменения сущностей хранятся в виде событий в отдельной БД.
- Расчет модели маршрутов кэшируются Redis
- Каждый из сервисов имеет модульные тесты.
- Интеграционные тесты выполняются bash скриптом.

## Стек

- Java 17, Spring Boot "3.2.3", Spring Cloud "2023.0.1", Testcontainers, Lombok, Mapstruct.
- PostgreSQL, Redis, Kafka.
- Swagger/OpenAPI, Spring Authorization Server, Docker Compose.

## Запуск

Для старта нужно запустить командную строку в корне директории проекта и выполнить сборку проекта. Во время сборки
сперва выполняются модульные тесты, а для их выполнения запускается Testcontainers. Убедитесь, что Docker запущен:

```
./gradlew build
```

После того как проект собран, воспользуемся Docker Compose для сборки Docker образов на основании описания
docker-compose.yml файла. Вызывается командой:

```
docker-compose build
```

Для запуска проекта может потребоваться разрешение на доступ к фалам конфигурации и init.sql. Собранные контейнеры
запускаются up командой в detach mode:

```
docker-compose up -d
```

Интеграционное тестирование выполняется bash скриптом который находится в корне проекта. Запустить его можно, на пример,
git-bash интерпретатором, который поставляется вместе с git. Для работы с json, который приходит в ответ от сервиса,
bash скрипт использует утилиту jq, она устанавливается в ОС отдельно. Запуск скрипта:

```
bash test-all.bash
```

После выполнения теста проект останавливается командой:

```
docker-compose down
```

Если вы ленивы как некто, то вместо запуска и остановки проекта при помощи docker-compose up/down, можно
запустить скрипт с параметрами "start stop" и он сперва запустит контейнера, протестирует систему, затем все контейнера
остановит:

```
bash test-all.bash start stop
```

SwaggerUI активированной системы доступен по адресу https://localhost:8443/openapi/webjars/swagger-ui/index.html Когда
ссылка открывается в браузере, то антивирус будет ругаться на самоподписанный сертификат: "Недопустимое имя сертификата"
или не будет ругаться если открыть в "инкогито" режиме. Чтобы открыть страницу с документацией, нужно дать это
разрешение. Для выполнения запросов к системе через пользовательский интерфейс, нужно залогиниться на встроенном
сервере авторизации с логином "u" и паролем "p".

## Архитектура взаимодействия

Доступ к сервису происходит по https с само-подписанным сертификатом. Для доступа к корневому сервису "Direct" нужно
авторизоваться, получить валидный JWT токен на Spring Authorization Server обеспечивающий SSO. Он выдает токен с правами
read или read/write.

![tls.png](doc%2Ftls.png)

Получение данных выполняется по GET запросу на синхронном не блокирующем стеке. Изменение данных выполняются REST,
DELETE запросами в асинхронном режиме. Ответ 202 - это подтверждение о получении события. События передаются брокер
сообщений Kafka. Topics сообщений разделены по сервисам и типам сообщений. Т.е. CRUD каждого сервиса приходит в
отдельном канале, R - read получается по GET, здесь пишу CRUD для упрощения.

![crud.png](doc%2Fcrud.png)

Есть отдельные каналы по сохранению изменений сущностей. Количество каналов может быть избыточно большим, и в начале
реализации нужно архитектурно разрешить вопрос, какие сообщения будут наиболее частыми, такие сообщения нужно разделить
по типам и адресам. События, которые генерируются не часто можно объединить в один topic и дать возможность нескольким
сервисам вычитывать из него все сообщения, выбирая адресованные именно ему. Но в целом, изоляция по сервисам является
более оправданным подходом.

Внутренняя коммуникация между сервисами, происходит асинхронно. Сервисы ничего не знают друг о друге. Ни количество
экземпляров одного сервиса ни его адреса. Только корневой сервис знает виртуальные DNS имена сервисов, всё это упрощает
администрирование системы.

![inside-flow.png](doc%2Finside-flow.png)

### Вариант нормального рабочего потока:

1. Модель заказ поступает в систему, сохраняется в сервисе Заказов.
2. Сервис Заказ публикует событие о Задаче на перемещение груза.
3. Это событие читает сервис управления Грузами.
4. Это событие читает сервис расчета Пути.

Задача опубликовалась и она выполняется независимо. Сервис Пути рассчитывает путь перемещения, по бизнес правилам, это
может быть самый короткий или самый быстрый маршруты. Сервис Грузов занят только организацией двух-фазной транзакцией.
Груз из одного места нужно переложить в другое. Сервис Грузов начинает транзакцию не дожидаясь сообщения от сервиса
Пути.

5. Сервис Пути публикует событие с Путем после выполнения расчетов.
6. Сервис Грузов публикует событие о грузе для Складов.
7. Сервис Из_Складов и В_Склад читают событие о грузе.
8. Из_ и В_ Склады публикуют по одному событию о возможности перемещения, резервируют место.
9. Сервис Грузов читает событие с Путём.
10. Сервис Грузов читает оба события от Из_Склад и В_Склад.

Теперь можно начинать перемещение, Путь известен и место под груз зарезервировано на складах.

11. Сервис Грузов публикует событие о перемещении.
12. Сервис ИЗ_Склада читает событие о перемещении, отгружает и ждет событие о доставке от В_Склад.
13. Сервис В_Склад публикует события о доставке.
14. Сервис ИЗ_Склада читает событие о перемещении В_Склад и фиксирует доставку.
15. Сервис Грузов читает событие о перемещении В_Склад.

На этом само перемещение закончилось и нужно изменить статус как груза, так и заказа. Для завершения нет необходимости в
сообщении от Из_Склада, достаточно одного сообщения от В_Склад.

16. Сервис Грузов публикует событие о доставке.
17. Сервис Заказов читает событие о доставке и фиксирует выполнение заказа.

4,5 реализовано в сервисе Route. Прочитанное сообщение используется для поиска в Redis кэше и расчета пути. Затем
публикует событие о результате работы.

### Двух-фазная транзакция:

Сервис Склад может быть физически разделен и находиться в разных регионах, обслуживая определенный диапазон
id складов. На Складе применяется redo и undo логи, оптимистическая транзакция в расчете на то, что большинство
транзакций будет выполнено успешно.

ИЗ_Склада, откуда груз: redo – т.е. место еще занято и когда груз доедет до склада назначения, тогда место освободится.
Redo – изменения не применяем, а применим снятие (withdrawal) после выполнения транзакции.

В_Склад, туда куда едет груз: undo – т.е. место уже занято, но информация может откатиться если отменится
доставка. Undo – изменения применяем сразу, но сохраняем информацию на откат в виде залога (deposit).

![two-phase.png](doc%2Ftwo-phase.png)

### Удаление и архивация информации

Для сохранения согласованности, нужно не удалять информацию полностью, а организовать отдельный поток событий для
сохранения consistency данных, связанных с заказами и перемещаемыми грузами. В текущей архитектуре, изменения
объекта публикуются в поток revise. Так же, объекты, которые удаляются из рабочей БД - помещаются в поток revise. Это
поток событий используется для последующей архивации и обеспечения текущей согласованности с id сущностей, на пример
orderId, не путать с id записи в БД. Для это нужен отдельный сервис для хранения архива и проверки orderId на
уникальность. А если еще немного порассуждать, то станем хранить изменения агрегата в noSQL EventStore и модель для
чтения из SQL БД, что приведет нас к популярному паттерну CQRS или DDD. 
